{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('volleyball-ml': conda)",
   "display_name": "Python 3.8.5 64-bit ('volleyball-ml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c30b36b8d550a859a8d0a1ee9d7da01957e1a188a0d80e6c684f5bae5519e194"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clean and organising the raw data scraped from https://stats.ncaa.org/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "source": [
    "# Clean Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year = 2019\n",
    "for root, dirs, files in os.walk(f'../../../data/ncaa/raw/{year}/team_game_by_game/'):\n",
    "    for f in files:\n",
    "        df = pd.read_csv(Path(root).joinpath(f), header=1)\n",
    "        df.drop(columns=[\"MP\", \"Attend\", \"BHE\", \"Unnamed: 20\"], inplace=True)\n",
    "        df.replace({'/':''}, regex=True, inplace=True)\n",
    "        df.fillna(0, inplace=True)\n",
    "        df[[\"Kills\", \"Errors\", \"Total Attacks\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\"]] = df[[\"Kills\", \"Errors\", \"Total Attacks\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\"]].astype(int)\n",
    "        outpath = Path(root).parent.parent.parent.joinpath(f\"processed/{year}/game_by_game_cleaned/\")\n",
    "        outpath.mkdir(parents=True, exist_ok=True)\n",
    "        f = f[:f.find('(') - 1] + \".csv\"\n",
    "        df.to_csv(outpath.joinpath(f), index=False)"
   ]
  },
  {
   "source": [
    "# Computing Moving Averages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Simple Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "\n",
    "year = 2019\n",
    "for root, dirs, files in os.walk(f'../../../data/ncaa/processed/{year}/game_by_game_cleaned'):\n",
    "    new_root = Path(root).parent.joinpath(f\"game_by_game_{window}_sma\")\n",
    "    new_root.mkdir(parents=True, exist_ok=True)\n",
    "    for f in files:\n",
    "        team_names.append(f[:-4])\n",
    "        df = pd.read_csv(Path(root).joinpath(f))\n",
    "        features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "        df[features] = df[features].rolling(window, min_periods=1).mean()\n",
    "        df.to_csv(new_root.joinpath(f), index=False)"
   ]
  },
  {
   "source": [
    "## Cumulative Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "for root, dirs, files in os.walk(f'../../../data/ncaa/processed/{year}/game_by_game_cleaned'):\n",
    "    new_root = Path(root).parent.joinpath(\"game_by_game_cma\")\n",
    "    new_root.mkdir(parents=True, exist_ok=True)\n",
    "    for f in files:\n",
    "        team_names.append(f[:-4])\n",
    "        df = pd.read_csv(Path(root).joinpath(f))\n",
    "        features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "        df[features] = df[features].expanding().mean()\n",
    "        df.to_csv(new_root.joinpath(f), index=False)"
   ]
  },
  {
   "source": [
    "## Exponential Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "alpha = 0.2\n",
    "for root, dirs, files in os.walk(f'../../../data/ncaa/processed/{year}/game_by_game_cleaned'):\n",
    "    new_root = Path(root).parent.joinpath(f\"game_by_game_{alpha}_ewm\")\n",
    "    new_root.mkdir(parents=True, exist_ok=True)\n",
    "    for f in files:\n",
    "        team_names.append(f[:-4])\n",
    "        df = pd.read_csv(Path(root).joinpath(f))\n",
    "        features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "        df[features] = df[features].ewm(alpha=alpha).mean()\n",
    "        df.to_csv(new_root.joinpath(f), index=False)"
   ]
  },
  {
   "source": [
    "# Combine into single dataframe of matches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Utility Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    if '@' in name:\n",
    "        if name.index('@') == 0:\n",
    "            return name[2:]\n",
    "        else:\n",
    "            return name[:name.index('@')-1]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "def combine(input_path, output_path):\n",
    "    dfs = []\n",
    "    team_names = []\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "            dfs.append(pd.read_csv(Path(root).joinpath(f)))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    err_a = 0\n",
    "    err_b = 0\n",
    "\n",
    "    features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "    combined_features = [\"Date\", \"TeamA\", \"TeamB\", \"Result\", \"S\", \"Team A Kills\", \"Team A Errors\", \"Team A Total Attacks\", \"Team A Hit Pct\", \"Team A Assists\", \"Team A Aces\", \"Team A SErr\", \"Team A Digs\", \"Team A RErr\", \"Team A Block Solos\", \"Team A Block Assists\", \"Team A BErr\", \"Team A PTS\", \"Team B Kills\", \"Team B Errors\", \"Team B Total Attacks\", \"Team B Hit Pct\", \"Team B Assists\", \"Team B Aces\", \"Team B SErr\", \"Team B Digs\", \"Team B RErr\", \"Team B Block Solos\", \"Team B Block Assists\", \"Team B BErr\", \"Team B PTS\"]\n",
    "\n",
    "    for i, name in enumerate(team_names):\n",
    "        df = dfs[i]\n",
    "        for j, TeamA_row in df.iterrows(): \n",
    "            date = TeamA_row[\"Date\"]\n",
    "            TeamA = name\n",
    "            TeamB = clean_name(TeamA_row[\"Opponent\"])\n",
    "            Result = 1 if TeamA_row[\"Result\"][0] == 'W' else 0\n",
    "            S = TeamA_row[\"S\"]\n",
    "            TeamA_stats = TeamA_row[features]\n",
    "            try:\n",
    "                TeamB_df = dfs[team_names.index(TeamB)]\n",
    "            except:\n",
    "                err_a += 1\n",
    "                continue\n",
    "            try:\n",
    "                TeamB_row = TeamB_df[TeamB_df[\"Date\"] == date][TeamB_df[\"Opponent\"].str.contains(TeamA)].reset_index().loc[0]\n",
    "            except:\n",
    "                err_b += 1\n",
    "                continue\n",
    "\n",
    "            TeamB_stats = TeamB_row[features]\n",
    "            data.append([date, TeamA, TeamB, Result, S, *TeamA_stats, *TeamB_stats])\n",
    "        \n",
    "    combined_df = pd.DataFrame(data, columns=combined_features)\n",
    "    combined_df.to_csv(output_path)\n",
    "    return combined_df, dict(err_a=err_a, err_b=err_b)"
   ]
  },
  {
   "source": [
    "## Combine dataframe of math by match result without any averages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'err_a': 368, 'err_b': 59} 9536\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "input_path = f'../../../data/ncaa/processed/{year}/game_by_game_cleaned'\n",
    "output_path = f'../../../data/ncaa/processed/{year}/accumulated/matches_gathered.csv'\n",
    "\n",
    "matches_gathered_df, info = combine(input_path, output_path)\n",
    "print(info, len(matches_gathered_df))"
   ]
  },
  {
   "source": [
    "## Combine dataframe for Simple Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'err_a': 368, 'err_b': 59} 9536\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "window = 10\n",
    "input_path = f'../../../data/ncaa/processed/{year}/game_by_game_{window}_sma'\n",
    "output_path = f'../../../data/ncaa/processed/{year}/accumulated/{window}_sma.csv'\n",
    "\n",
    "sma_df, info = combine(input_path, output_path)\n",
    "print(info, len(sma_df))"
   ]
  },
  {
   "source": [
    "## Combine dataframe for Cumulative Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'err_a': 368, 'err_b': 59} 9536\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "input_path = f'../../../data/ncaa/processed/{year}/game_by_game_cma'\n",
    "output_path = f'../../../data/ncaa/processed/{year}/accumulated/cma.csv'\n",
    "\n",
    "cma_df, info = combine(input_path, output_path)\n",
    "print(info, len(cma_df))"
   ]
  },
  {
   "source": [
    "## Combine dataframe for Exponentially Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'err_a': 368, 'err_b': 59} 9536\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "alpha = 0.2\n",
    "input_path = f'../../../data/ncaa/processed/{year}/game_by_game_{alpha}_ewm'\n",
    "output_path = f'../../../data/ncaa/processed/{year}/accumulated/{alpha}_ewm.csv'\n",
    "\n",
    "ewm_df, info = combine(input_path, output_path)\n",
    "print(info, len(ewm_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}